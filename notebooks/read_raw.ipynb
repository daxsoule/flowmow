{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read_raw\n",
    "\n",
    "This notebook reads the raw FlowMow2 Sentry data into Pandas dataframes and saves them to HDF5 files. This notebook does not do any processing on the data aside from assigning timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flowmow\n",
    "import pandas as pd\n",
    "from dask import delayed\n",
    "from dask import compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=10)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('../data/info/ashes_nav.csv', header=None, names=['filename', 'blob_id', 'dive_number'])\n",
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_delayed = []\n",
    "for index, row in files.iterrows():\n",
    "    nav_delayed.append(delayed(flowmow.read_nav)(row.blob_id, row.dive_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nav = pd.concat(compute(*nav_delayed)).sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to hdf5\n",
    "nav.to_hdf('../data/interim/nav.h5', 'table', append=False, data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Paros pressure sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('../data/info/ashes_paros.csv', header=None, names=['filename', 'blob_id', 'dive_number'])\n",
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paros_delayed = []\n",
    "for index, row in files.iterrows():\n",
    "    paros_delayed.append(delayed(flowmow.read_paros)(row.blob_id, row.dive_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paros = pd.concat(compute(*paros_delayed)).sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to hdf5\n",
    "paros.to_hdf('../data/interim/paros.h5', 'table', append=False, data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import stinger GX3-25 microstrain IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('../data/info/ashes_ustrain_adv.csv', header=None, names=['filename', 'blob_id', 'dive_number'])\n",
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustrain_adv_delayed = []\n",
    "for index, row in files.iterrows():\n",
    "    ustrain_adv_delayed.append(delayed(flowmow.read_ustrain)(row.blob_id, row.dive_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ustrain_adv = pd.concat(compute(*ustrain_adv_delayed)).sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustrain_adv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to hdf5\n",
    "ustrain_adv.to_hdf('../data/interim/ustrain_adv.h5', 'table', append=False, data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import chassis GX3-25 microstrain IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('../data/info/ashes_ustrain_chassis.csv', header=None, names=['filename', 'blob_id', 'dive_number'])\n",
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustrain_chassis_delayed = []\n",
    "for index, row in files.iterrows():\n",
    "    ustrain_chassis_delayed.append(delayed(flowmow.read_ustrain)(row.blob_id, row.dive_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ustrain_chassis = pd.concat(compute(*ustrain_chassis_delayed)).sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustrain_chassis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to hdf5\n",
    "ustrain_chassis.to_hdf('../data/interim/ustrain_chassis.h5', 'table', append=False, data_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import SBE3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_csv('../data/info/ashes_sbe3.csv', header=None, names=['filename', 'blob_id', 'dive_number'])\n",
    "files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe3_delayed = []\n",
    "for index, row in files.iterrows():\n",
    "    sbe3_delayed.append(delayed(flowmow.read_sbe3)(row.blob_id, row.dive_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sbe3 = pd.concat(compute(*sbe3_delayed)).sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to hdf5\n",
    "sbe3.to_hdf('../data/interim/sbe3.h5', 'table', append=False, data_columns=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
