{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read_raw\n",
    "\n",
    "This notebook reads the raw FlowMow Sentry data into Pandas dataframes and saves them to HDF5 files using HDFStore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import glob\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp extractor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(line):\n",
    "    timestamp = dt.datetime.strptime(' '.join(line.strip().split(' ')[1:3]), '%Y/%m/%d %H:%M:%S.%f')\n",
    "    epoch = timestamp.replace(tzinfo=dt.timezone.utc).timestamp()\n",
    "    return timestamp, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import SCC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filenames = glob.glob('/home/tjc/research/flowmow/**/*.scc', recursive=True)\n",
    "filenames.sort()\n",
    "scc_list = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'SCC' in line.strip()[0:3]:\n",
    "                timestamp, epoch = get_timestamp(line)\n",
    "                scc_list.append([timestamp, epoch] + list(map(np.float64, line.strip().split(' ')[3:])))           \n",
    "scc = pd.DataFrame(scc_list, columns=['timestamp','epoch','lat','lon','depth','pressure','heading',\n",
    "                                      'magx','magy','magz','obs','eh','aux1','aux2','T1','C1',\n",
    "                                      'T2','C2','S1','S2','ss1','depth_d','height','D1','D2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use GMT to get UTM values for Sentry navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tmpfile = dt.datetime.now().strftime(\"utmx_utmy_%Y%m%d%H%M%S%f\")\n",
    "scc.to_csv(tmpfile, sep=',', columns = ['lon', 'lat'], header=False, index=False)\n",
    "cmd = 'cat %s | gmt mapproject -Ju9/1 -R-132/-126/40/48 -F' % tmpfile\n",
    "gmt_output = (subprocess.check_output(cmd, shell=True).decode('utf-8')).split('\\n')\n",
    "os.remove(tmpfile)\n",
    "os.remove('gmt.history')\n",
    "\n",
    "utm_x = []\n",
    "utm_y = []\n",
    "for i in gmt_output:\n",
    "    try:\n",
    "        utm_x.append(np.float64(i.split('\\t')[0]))\n",
    "        utm_y.append(np.float64(i.split('\\t')[1]))\n",
    "    except:\n",
    "        pass\n",
    "scc.insert(4, 'utm_x', utm_x)\n",
    "scc.insert(5, 'utm_y', utm_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save SCC to an HDF5 store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "store = pd.HDFStore('flowmow.h5')\n",
    "store['scc'] = scc\n",
    "store.flush(fsync=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Paros pressure sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filenames = glob.glob('/home/tjc/research/flowmow/**/parosKinsey/*.DAT', recursive=True)\n",
    "filenames.sort()\n",
    "paros_list = []\n",
    "i = 0\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'RAW' in line.strip()[0:3]:\n",
    "                if 'P2=' in line.strip():\n",
    "                    timestamp, epoch = get_timestamp(line)\n",
    "                    a = line.strip().split(' ')[3].split(',')[0].split('=')[1]\n",
    "                    b = line.strip().split(' ')[3].split(',')[1]\n",
    "                    paros_list.append([timestamp,epoch,a,b])\n",
    "                    i = i+1\n",
    "paros = pd.DataFrame(paros_list, columns=['timestamp', 'epoch', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push paros to the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "store['paros'] = paros\n",
    "store.flush(fsync=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
